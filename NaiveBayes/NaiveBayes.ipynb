{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMw0sJ-v9SNr"
      },
      "source": [
        "**Spam Filtering using Multinomial Naive Bayes**\n",
        "\n",
        "For spam filtering, we use another variation of Naive Bayes i.e. Multinomial Naive Bayes Clssifier where the likelihoods are computed as-\n",
        "\n",
        "$$\n",
        "P(w_i|\\lambda) = \\dfrac{N_{w_i|\\lambda} + \\alpha}{N_{\\lambda} + \\alpha N_{vocabulary}}\n",
        "$$\n",
        "where $w_i$ is the word whose likelihood is to be calculated and $\\lambda$ represents a class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZqGztF86t97"
      },
      "source": [
        "# Multinomial Naive Bayes Model\n",
        "class MyMultinomialNB:\n",
        "\n",
        "    def __init__(self, filepath):\n",
        "        np.random.seed(1234)\n",
        "        self.data = pd.read_csv(filepath, sep='\\t', header=None, names=['labels', 'sms'])   # read data\n",
        "        print(self.data.shape)\n",
        "        print(self.data.head(), end='\\n\\n')\n",
        "        self.class_probabs = dict()\n",
        "        self.vocab = None\n",
        "        self.word_count = None\n",
        "        self.num_spam = 0\n",
        "        self.num_ham = 0\n",
        "        self.vocab_size = 0\n",
        "        self.alpha = 1\n",
        "\n",
        "    def preprocess(self, split=0.8):\n",
        "        self.data['sms'] = self.data['sms'].str.replace('\\W+', ' ')   # replace non-word characters with a space\n",
        "        self.data['sms'] = self.data['sms'].str.replace('\\s+', ' ')   # relace multiple spaces with single space\n",
        "        self.data['sms'] = self.data['sms'].str.strip()   # remove leading and trailing whitespaces\n",
        "        self.data['sms'] = self.data['sms'].str.lower()   # make all characters lower case\n",
        "        self.data['sms'] = self.data['sms'].str.split()   # break words on spaces to form a list\n",
        "        # print(self.data.head())\n",
        "\n",
        "        indices = np.arange(self.data.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "        self.train_data, self.test_data = self.data.iloc[indices[:int(split * len(indices))], :].reset_index(drop=True), self.data.iloc[indices[int(split * len(indices)):], :].reset_index(drop=True)  # split train and test data\n",
        "        \n",
        "        print(f'Training data: {self.train_data.shape[0]}')\n",
        "        print(f'Test data: {self.test_data.shape[0]}')\n",
        "\n",
        "        # split message and labels\n",
        "        self.X_train, self.y_train = self.train_data.iloc[:, 1], self.train_data.iloc[:, 0] \n",
        "        self.X_test, self.y_test = self.test_data.iloc[:, 1], self.test_data.iloc[:, 0]\n",
        "\n",
        "        return self.X_train, self.y_train, self.X_test, self.y_test\n",
        "    \n",
        "    def fit(self):\n",
        "        self.class_probabs = self.y_train.value_counts(normalize=True)  # calculate class prior probabilities\n",
        "        print(f'Class Probabilities:\\n{self.class_probabs}')\n",
        "        self.vocab = list(set(self.X_train.sum()))  # create vocabulary\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        print(f'Vocabulary length: {self.vocab_size}')\n",
        "        self.word_count = pd.DataFrame([[self.X_train.iloc[i].count(word) for word in self.vocab] for i in range(self.X_train.shape[0])], columns=self.vocab)   # count the number of times each word has appeare in a message\n",
        "        self.X_train = pd.concat([self.X_train, self.word_count], axis=1).iloc[:, 1:]   # update train features\n",
        "        # print(self.X_train.head())\n",
        "    \n",
        "    # calculate likelihood of a word for spam class\n",
        "    def p_w_spam(self, word):\n",
        "        if word in self.vocab:\n",
        "            return (self.X_train.loc[self.y_train == 'spam', word].sum() + self.alpha) / ((self.y_train == 'spam').sum() + self.alpha * self.vocab_size)\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    # calculate likelihood of a word for ham class\n",
        "    def p_w_ham(self, word):\n",
        "        if word in self.vocab:\n",
        "            return (self.X_train.loc[self.y_train == 'ham', word].sum() + self.alpha) / ((self.y_train == 'ham').sum() + self.alpha * self.vocab_size)\n",
        "        else:\n",
        "            return 1\n",
        "    \n",
        "    def predict(self, text):\n",
        "        p_spam = self.class_probabs['spam']\n",
        "        p_ham = self.class_probabs['ham']\n",
        "        for word in text:\n",
        "            p_spam *= self.p_w_spam(word)   # compute probability of message belonging to spam\n",
        "            p_ham *= self.p_w_ham(word) # compute probability of message belonging to ham\n",
        "\n",
        "        # predict\n",
        "        if p_spam > p_ham:\n",
        "            return 'spam'\n",
        "        elif p_ham > p_spam:\n",
        "            return 'ham'\n",
        "        else:\n",
        "            return 'can not classify'\n",
        "        \n",
        "    def test(self, test_data=None):\n",
        "        # test\n",
        "        predictions = []\n",
        "        if test_data == None:\n",
        "            for i in range(self.X_test.shape[0]):\n",
        "                predictions.append(self.predict(self.X_test.iloc[i]))\n",
        "            print(f'Accuracy = {(self.y_test == np.array(predictions)).sum()/len(predictions)}')\n",
        "    \n",
        "    def get_params(self):\n",
        "        #return parameters\n",
        "        return self.class_probabs, self.vocab, self.X_train, self.y_train"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHii6DOT9Q8H"
      },
      "source": [
        "Processing data and fitting modelÂ¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUD1crOi9sgG",
        "outputId": "4a62666e-a1a9-4c21-8ebd-0548b7261af5"
      },
      "source": [
        "mnb = MyMultinomialNB('/content/SMSSpamCollection')\n",
        "X_train, y_train, X_test, y_test = mnb.preprocess()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 2)\n",
            "  labels                                                sms\n",
            "0    ham  Go until jurong point, crazy.. Available only ...\n",
            "1    ham                      Ok lar... Joking wif u oni...\n",
            "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    ham  U dun say so early hor... U c already then say...\n",
            "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
            "\n",
            "Training data: 4457\n",
            "Test data: 1115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXbMLBf2-T4_",
        "outputId": "f7d37173-ba2b-4d85-bc08-9ede55734ccf"
      },
      "source": [
        "mnb.fit()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Probabilities:\n",
            "ham     0.869419\n",
            "spam    0.130581\n",
            "Name: labels, dtype: float64\n",
            "Vocabulary length: 7823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_OK8_9F-bIL",
        "outputId": "91c1bb7e-58c7-47e1-e8cb-8fc904062ab8"
      },
      "source": [
        "mnb.test()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9632286995515695\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}